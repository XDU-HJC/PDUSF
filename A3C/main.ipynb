{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "ACTION_SIZE = 4\n",
    "SCREEN_WIDTH = 84\n",
    "SCREEN_HEIGHT = 84\n",
    "HISTORY_LENGTH = 4\n",
    "\n",
    "class THORDiscreteEnvironment(object):\n",
    "\n",
    "  def __init__(self, config=dict()):\n",
    "\n",
    "    # configurations\n",
    "    self.scene_name          = config.get('scene_name', 'bathroom_03')\n",
    "    self.random_start        = config.get('random_start', True)\n",
    "    self.n_feat_per_locaiton = config.get('n_feat_per_locaiton', 1) # 1 for no sampling\n",
    "    self.terminal_state_id   = config.get('terminal_state_id', 0)\n",
    "\n",
    "    self.h5_file_path = config.get('h5_file_path', 'data/%s.h5'%self.scene_name)\n",
    "    self.h5_file      = h5py.File(self.h5_file_path, 'r')\n",
    "\n",
    "    self.locations   = self.h5_file['location'][()]\n",
    "    self.rotations   = self.h5_file['rotation'][()]\n",
    "    self.n_locations = self.locations.shape[0]\n",
    "\n",
    "    self.terminals = np.zeros(self.n_locations)\n",
    "    self.terminals[self.terminal_state_id] = 1\n",
    "    self.terminal_states, = np.where(self.terminals)\n",
    "\n",
    "    self.transition_graph = self.h5_file['graph'][()]\n",
    "    self.shortest_path_distances = self.h5_file['shortest_path_distance'][()]\n",
    "\n",
    "    self.history_length = HISTORY_LENGTH\n",
    "    self.screen_height  = SCREEN_HEIGHT\n",
    "    self.screen_width   = SCREEN_WIDTH\n",
    "\n",
    "    # we use pre-computed fc7 features from ResNet-50\n",
    "    # self.s_t = np.zeros([self.screen_height, self.screen_width, self.history_length])\n",
    "    self.s_t      = np.zeros([2048, self.history_length])\n",
    "    self.s_t1     = np.zeros_like(self.s_t)\n",
    "    self.s_target = self._tiled_state(self.terminal_state_id)\n",
    "\n",
    "    self.reset()\n",
    "\n",
    "  # public methods\n",
    "\n",
    "  def reset(self):\n",
    "    # randomize initial state\n",
    "    while True:\n",
    "      k = random.randrange(self.n_locations)\n",
    "      min_d = np.inf\n",
    "      # check if target is reachable\n",
    "      for t_state in self.terminal_states:\n",
    "        dist = self.shortest_path_distances[k][t_state]\n",
    "        min_d = min(min_d, dist)\n",
    "      # min_d = 0  if k is a terminal state\n",
    "      # min_d = -1 if no terminal state is reachable from k\n",
    "      if min_d > 0: break\n",
    "\n",
    "    # reset parameters\n",
    "    self.current_state_id = k\n",
    "    self.s_t = self._tiled_state(self.current_state_id)\n",
    "    self.s_target = self._tiled_state(self.terminal_state_id)\n",
    "\n",
    "    self.reward = 0\n",
    "    self.collided = False\n",
    "    self.terminal = False\n",
    "    self.s_t_reshape = self.s_t.reshape(-1, 8192)\n",
    "    self.s_target_reshape = self.s_target.reshape(-1, 8192)\n",
    "\n",
    "\n",
    "    # return self.s_t_reshape, self.s_target_reshape\n",
    "    return self.s_t_reshape, self.s_target_reshape, min_d\n",
    "\n",
    "  def step(self, action):\n",
    "    assert not self.terminal, 'step() called in terminal state'\n",
    "    k = self.current_state_id\n",
    "    if self.transition_graph[k][action] != -1:\n",
    "      self.current_state_id = self.transition_graph[k][action]\n",
    "      if self.terminals[self.current_state_id]:\n",
    "        self.terminal = True\n",
    "        self.collided = False\n",
    "      else:\n",
    "        self.terminal = False\n",
    "        self.collided = False\n",
    "    else:\n",
    "      self.terminal = False\n",
    "      self.collided = True\n",
    "\n",
    "    self.reward = self._reward(self.terminal, self.collided)\n",
    "    self.s_t1 = np.append(self.s_t[:,1:], self.state, axis=1)\n",
    "\n",
    "    self.s_t1_reshape = self.s_t1.reshape(-1, 8192)\n",
    "    return self.s_t1_reshape, self.reward, self.terminal, self.current_state_id, self.collided\n",
    "    \n",
    "\n",
    "  def update(self):\n",
    "    self.s_t = self.s_t1\n",
    "\n",
    "  # private methods\n",
    "\n",
    "  def _tiled_state(self, state_id):\n",
    "    k = random.randrange(self.n_feat_per_locaiton)\n",
    "    f = self.h5_file['resnet_feature'][state_id][k][:,np.newaxis]\n",
    "    return np.tile(f, (1, self.history_length))\n",
    "\n",
    "  def _reward(self, terminal, collided):\n",
    "    # positive reward upon task completion\n",
    "    if terminal:\n",
    "      return 10\n",
    "    elif collided:\n",
    "      return -0.1\n",
    "    else:\n",
    "      return -0.01\n",
    "  # properties\n",
    "\n",
    "  @property\n",
    "  def action_size(self):\n",
    "    # move forward/backward, turn left/right for navigation\n",
    "    return ACTION_SIZE \n",
    "\n",
    "  @property\n",
    "  def action_definitions(self):\n",
    "    action_vocab = [\"MoveForward\", \"RotateRight\", \"RotateLeft\", \"MoveBackward\"]\n",
    "    return action_vocab[:ACTION_SIZE]\n",
    "\n",
    "  @property\n",
    "  def observation(self):\n",
    "    obs = self.h5_file['observation'][self.current_state_id]\n",
    "    # return self.h5_file['observation'][self.current_state_id]\n",
    "    return obs\n",
    "\n",
    "  @property\n",
    "  def state(self):\n",
    "    # read from hdf5 cache\n",
    "    k = random.randrange(self.n_feat_per_locaiton)\n",
    "    return self.h5_file['resnet_feature'][self.current_state_id][k][:,np.newaxis]\n",
    "\n",
    "  @property\n",
    "  def target(self):\n",
    "    return self.s_target\n",
    "\n",
    "  @property\n",
    "  def x(self):\n",
    "    return self.locations[self.current_state_id][0]\n",
    "\n",
    "  @property\n",
    "  def z(self):\n",
    "    return self.locations[self.current_state_id][1]\n",
    "\n",
    "  @property\n",
    "  def r(self):\n",
    "    return self.rotations[self.current_state_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  scene_name = 'bathroom_02'\n",
    "  env = THORDiscreteEnvironment({\n",
    "    'random_start': True,\n",
    "    'scene_name': scene_name,\n",
    "    'h5_file_path': 'data/%s.h5'%scene_name\n",
    "  })\n",
    "  # obs = env.observation()\n",
    "  # print(type(obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyglet\n",
    "\n",
    "class SimpleImageViewer(object):\n",
    "\n",
    "  def __init__(self, display=None):\n",
    "    self.window = None\n",
    "    self.isopen = False\n",
    "    self.display = display\n",
    "\n",
    "  def imshow(self, arr):\n",
    "    if self.window is None:\n",
    "      height, width, channels = arr.shape\n",
    "      self.window = pyglet.window.Window(width=width, height=height, display=self.display, caption=\"THOR Browser\")\n",
    "      self.width = width\n",
    "      self.height = height\n",
    "      self.isopen = True\n",
    "\n",
    "    assert arr.shape == (self.height, self.width, 3), \"You passed in an image with the wrong number shape\"\n",
    "    image = pyglet.image.ImageData(self.width, self.height, 'RGB', arr.tobytes(), pitch=self.width * -3)\n",
    "    self.window.clear()\n",
    "    self.window.switch_to()\n",
    "    self.window.dispatch_events()\n",
    "    image.blit(0,0)\n",
    "    self.window.flip()\n",
    "\n",
    "  def close(self):\n",
    "    if self.isopen:\n",
    "      self.window.close()\n",
    "      self.isopen = False\n",
    "\n",
    "  def __del__(self):\n",
    "    self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from scene_loader import THORDiscreteEnvironment\n",
    "# from utils.tools import SimpleImageViewer\n",
    "from tools import SimpleImageViewer\n",
    "\n",
    "#\n",
    "# Navigate the scene using your keyboard\n",
    "#\n",
    "\n",
    "def key_press(key, mod):\n",
    "\n",
    "  global human_agent_action, human_wants_restart, stop_requested\n",
    "  if key == ord('R') or key == ord('r'): # r/R\n",
    "    human_wants_restart = True\n",
    "  if key == ord('Q') or key == ord('q'): # q/Q\n",
    "    stop_requested = True\n",
    "  if key == 0xFF52: # up\n",
    "    human_agent_action = 0\n",
    "  if key == 0xFF53: # right\n",
    "    human_agent_action = 1\n",
    "  if key == 0xFF51: # left\n",
    "    human_agent_action = 2\n",
    "  if key == 0xFF54: # down\n",
    "    human_agent_action = 3\n",
    "\n",
    "def rollout(env):\n",
    "\n",
    "  global human_agent_action, human_wants_restart, stop_requested\n",
    "  human_agent_action = None\n",
    "  human_wants_restart = False\n",
    "  while True:\n",
    "    # waiting for keyboard input\n",
    "    if human_agent_action is not None:\n",
    "      # move actions\n",
    "      env.step(human_agent_action)\n",
    "      human_agent_action = None\n",
    "\n",
    "    # waiting for reset command\n",
    "    if human_wants_restart:\n",
    "      # reset agent to random location\n",
    "      env.reset()\n",
    "      human_wants_restart = False\n",
    "\n",
    "    # check collision\n",
    "    if env.collided:\n",
    "      print('Collision occurs.')\n",
    "      env.collided = False\n",
    "\n",
    "    # check quit command\n",
    "    if stop_requested: break\n",
    "\n",
    "    viewer.imshow(env.observation)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"-s\", \"--scene_dump\", type=str, default=\"./data/bedroom_04.h5\",\n",
    "                      help=\"path to a hdf5 scene dump file\")\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  print(\"Loading scene dump {}\".format(args.scene_dump))\n",
    "  env = THORDiscreteEnvironment({\n",
    "    'h5_file_path': args.scene_dump\n",
    "  })\n",
    "\n",
    "  # manually disable terminal states\n",
    "  env.terminals = np.zeros_like(env.terminals)\n",
    "  env.terminal_states, = np.where(env.terminals)\n",
    "  env.reset()\n",
    "\n",
    "  human_agent_action = None\n",
    "  human_wants_restart = False\n",
    "  stop_requested = False\n",
    "\n",
    "  img = Image.fromarray(env.observation, 'RGB')\n",
    "  # img.save(\"10.jpg\") \n",
    "\n",
    "  viewer = SimpleImageViewer()\n",
    "  viewer.imshow(env.observation)\n",
    "  viewer.window.on_key_press = key_press\n",
    "\n",
    "  print(\"Use arrow keys to move the agent.\")\n",
    "  print(\"Press R to reset agent\\'s location.\")\n",
    "  print(\"Press Q to quit.\")\n",
    "\n",
    "  rollout(env)\n",
    "\n",
    "  print(\"Goodbye.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def normalized_columns_initializer(weights, std=1.0):\n",
    "    out = torch.randn(weights.size())\n",
    "    out *= std / torch.sqrt(out.pow(2).sum(1, keepdim=True))\n",
    "    return out\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        weight_shape = list(m.weight.data.size())\n",
    "        fan_in = np.prod(weight_shape[1:4])\n",
    "        fan_out = np.prod(weight_shape[2:4]) * weight_shape[0]\n",
    "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        m.weight.data.uniform_(-w_bound, w_bound)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        weight_shape = list(m.weight.data.size())\n",
    "        fan_in = weight_shape[1]\n",
    "        fan_out = weight_shape[0]\n",
    "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        m.weight.data.uniform_(-w_bound, w_bound)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class ActorCritic(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        # FC and embedding\n",
    "        self.fc1 = nn.Linear(8192, 512)\n",
    "        self.embedding_layer = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "\n",
    "        self.critic_linear = nn.Linear(512, 1)\n",
    "        self.actor_linear = nn.Linear(512, 4)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "        self.actor_linear.weight.data = normalized_columns_initializer(self.actor_linear.weight.data, 0.01)\n",
    "        self.actor_linear.bias.data.fill_(0)\n",
    "        self.critic_linear.weight.data = normalized_columns_initializer(self.critic_linear.weight.data, 0.5)\n",
    "        self.critic_linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, state_input, target_input):\n",
    "        # siamese\n",
    "        state_input = state_input.reshape(state_input.size(0), -1)\n",
    "        target_input = target_input.reshape(target_input.size(0), -1)\n",
    "\n",
    "        h1_s = F.relu(self.fc1(state_input))\n",
    "        h1_t = F.relu(self.fc1(target_input))\n",
    "\n",
    "        input_embedding = torch.cat((h1_s, h1_t), -1)\n",
    "        h2_e = F.relu(self.embedding_layer(input_embedding))\n",
    "\n",
    "        h3 = F.relu(self.fc2(h2_e))\n",
    "\n",
    "        value_output = self.critic_linear(h3)\n",
    "        logit_output = self.actor_linear(h3)\n",
    "\n",
    "        return value_output, logit_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38742/432797618.py:109: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      "epi_length: 1113\n",
      "episode: 0\n",
      "epi_length: 202\n",
      "episode: 0\n",
      "epi_length: 1482\n",
      "episode: 0\n",
      "epi_length: 210\n",
      "episode: 0\n",
      "epi_length: 722\n",
      "episode: 1\n",
      "epi_length: 296\n",
      "episode: 1\n",
      "epi_length: 1105\n",
      "episode: 1\n",
      "epi_length: 236\n",
      "episode: 1\n",
      "epi_length: 200\n",
      "episode: 1\n",
      "epi_length: 33\n",
      "episode: 2\n",
      "epi_length: 947\n",
      "episode: 2\n",
      "epi_length: 44\n",
      "episode: 2\n",
      "epi_length: 697\n",
      "episode: 2\n",
      "epi_length: 110\n",
      "episode: 2\n",
      "epi_length: 342\n",
      "episode: 3\n",
      "epi_length: 629\n",
      "episode: 3\n",
      "epi_length: 250\n",
      "episode: 3\n",
      "epi_length: 876\n",
      "episode: 3\n",
      "epi_length: 150\n",
      "episode: 3\n",
      "epi_length: 800\n",
      "episode: 4\n",
      "epi_length: 832\n",
      "episode: 4\n",
      "epi_length: 136\n",
      "episode: 4\n",
      "epi_length: 331\n",
      "episode: 4\n",
      "epi_length: 8\n",
      "episode: 4\n",
      "epi_length: 384\n",
      "episode: 5\n",
      "epi_length: 75\n",
      "episode: 5\n",
      "epi_length: 923\n",
      "episode: 5\n",
      "epi_length: 112\n",
      "episode: 5\n",
      "epi_length: 191\n",
      "episode: 5\n",
      "epi_length: 188\n",
      "episode: 6\n",
      "epi_length: 699\n",
      "episode: 6\n",
      "epi_length: 1131\n",
      "episode: 6\n",
      "epi_length: 26\n",
      "episode: 6\n",
      "epi_length: 3000\n",
      "episode: 6\n",
      "epi_length: 356\n",
      "episode: 7\n",
      "epi_length: 1899\n",
      "episode: 7\n",
      "epi_length: 220\n",
      "episode: 7\n",
      "epi_length: 604\n",
      "episode: 7\n",
      "epi_length: 105\n",
      "episode: 7\n",
      "epi_length: 218\n",
      "episode: 8\n",
      "epi_length: 14\n",
      "episode: 8\n",
      "epi_length: 1010\n",
      "episode: 8\n",
      "epi_length: 3000\n",
      "episode: 8\n",
      "epi_length: 1033\n",
      "episode: 8\n",
      "epi_length: 612\n",
      "episode: 9\n",
      "epi_length: 226\n",
      "episode: 9\n",
      "epi_length: 3000\n",
      "episode: 9\n",
      "epi_length: 130\n",
      "episode: 9\n",
      "epi_length: 283\n",
      "episode: 9\n",
      "epi_length: 399\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from network import ActorCritic\n",
    "from scene_loader import THORDiscreteEnvironment as Environment\n",
    "import torch.nn.functional as F\n",
    "scene_scope = 'bathroom_02'\n",
    "task_scopes = ['26', '37', '43', '53', '69']\n",
    "\n",
    "'''\n",
    "    ls_scene_scope = ['bathroom_02', 'bedroom_04', 'kitchen_02', 'living_room_08']\n",
    "    TASK_LIST = {\n",
    "                    'bathroom_02'    : ['26', '37', '43', '53', '69'],\n",
    "                    'bedroom_04'     : ['134', '264', '320', '384', '387'],\n",
    "                    'kitchen_02'     : ['90', '136', '157', '207', '329'],\n",
    "                    'living_room_08' : ['92', '135', '193', '228', '254']\n",
    "    }\n",
    "'''\n",
    "lr = 0.0001\n",
    "num_episodes = 10\n",
    "ep_len = 100\n",
    "gamma = 0.99\n",
    "return_list = []\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = ActorCritic().to(device)\n",
    "# checkpoint = torch.load('./model/%s.pth' % (scene_scope))\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    for task_scope in task_scopes:\n",
    "        env = Environment({'scene_name': scene_scope, 'terminal_state_id': int(task_scope)})\n",
    "        state, target, _ = env.reset()\n",
    "        state = torch.tensor(state).to(device)\n",
    "        target = torch.tensor(target).to(device)\n",
    "        episode_length = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            values =[]\n",
    "            states = []\n",
    "            targets = []\n",
    "            actions = []\n",
    "            probs = []\n",
    "            rewards = []\n",
    "            for step in range(ep_len):\n",
    "                episode_length += 1\n",
    "                states.append(state)\n",
    "                targets.append(targets)\n",
    "                value, logit = model(state, target)\n",
    "                prob = F.softmax(logit, dim=-1)\n",
    "                action = prob.multinomial(num_samples=1).detach()\n",
    "\n",
    "                state, reward, done, current_state_id, collide = env.step(action)\n",
    "                done = done or episode_length >= 3000\n",
    "                reward = max(min(reward, 1), -1)\n",
    "\n",
    "                state = torch.tensor(state).to(device)\n",
    "\n",
    "\n",
    "                values.append(value)\n",
    "                actions.append(action)\n",
    "                probs.append(prob)\n",
    "                rewards.append(reward)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            R = 0.0\n",
    "            if not done:\n",
    "                R, _ = model(state, target)\n",
    "\n",
    "            values.reverse()\n",
    "            rewards.reverse()\n",
    "            actions.reverse()\n",
    "            states.reverse()\n",
    "            probs.reverse()\n",
    "\n",
    "            batch_si = []\n",
    "            batch_a = []\n",
    "            batch_td = []\n",
    "            batch_R = []\n",
    "            batch_t = []\n",
    "\n",
    "\n",
    "            for (ai, ri, vi, si, ti) in zip(actions, rewards, values, states, targets):\n",
    "                R = ri + gamma * R\n",
    "                td = R - vi\n",
    "                a = np.zeros(4)\n",
    "                a[ai] = 1\n",
    "\n",
    "                batch_a.append(a)\n",
    "                batch_R.append(R)\n",
    "                batch_td.append(td)\n",
    "                batch_si.append(si)\n",
    "                batch_t.append(ti)\n",
    "\n",
    "            batch_a = torch.tensor(batch_a).to(device)\n",
    "            batch_R = torch.tensor(batch_R).to(device)\n",
    "            batch_td = torch.tensor(batch_td).to(device)\n",
    "\n",
    "            pi = torch.cat(probs, dim=0)\n",
    "            log_pi = torch.log(torch.clamp(pi, 1e-20, 1.0))\n",
    "            entroy = -torch.sum(pi * log_pi, dim=1)\n",
    "            policy_loss = -torch.sum(torch.sum(log_pi * batch_a, dim=1) * batch_td + 0.01 * entroy)\n",
    "            value_loss = 0.5 * torch.sum(batch_td)**2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            (policy_loss + 0.5 * value_loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 50)\n",
    "            optimizer.step()\n",
    "\n",
    "        print('episode:', episode)\n",
    "        print('epi_length:', episode_length)\n",
    "\n",
    "# checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "# torch.save(checkpoint, './model/%s.pth' % (scene_scope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR: 100.0\n",
      "SPL: 68.5827070611095\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from network import ActorCritic\n",
    "from scene_loader import THORDiscreteEnvironment as Environment\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "scope = 'bedroom_04'\n",
    "\n",
    "scene_scope = 'bedroom_04'\n",
    "task_scopes = ['134', '264', '320', '384', '387']\n",
    "\n",
    "'''\n",
    "    ls_scene_scope = ['bathroom_02', 'bedroom_04', 'kitchen_02', 'living_room_08']\n",
    "    TASK_LIST = {\n",
    "                    'bathroom_02'    : ['26', '37', '43', '53', '69'],\n",
    "                    'bedroom_04'     : ['134', '264', '320', '384', '387'],\n",
    "                    'kitchen_02'     : ['90', '136', '157', '207', '329'],\n",
    "                    'living_room_08' : ['92', '135', '190', '228', '254']\n",
    "    }\n",
    "'''\n",
    "model = ActorCritic().to(device)\n",
    "checkpoint = torch.load('./model/%s.pth' % (scope))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "NUM_EVAL_EPISODES = 10\n",
    "MAX_STEP = 500\n",
    "ep_lengths = []\n",
    "min_length = []\n",
    "\n",
    "for i in range(NUM_EVAL_EPISODES):\n",
    "    for task_scope in task_scopes:\n",
    "        env = Environment({'scene_name': scene_scope, 'terminal_state_id': int(task_scope)})\n",
    "        state, target, min_dist = env.reset()\n",
    "        state = torch.tensor(state).to(device)\n",
    "        target = torch.tensor(target).to(device)\n",
    "        min_length.append(min_dist)\n",
    "        episode_length = 0\n",
    "        for step in range(MAX_STEP):\n",
    "            episode_length += 1\n",
    "            with torch.no_grad():\n",
    "                value, logit = model(state, target)\n",
    "            prob = F.softmax(logit, dim=-1)\n",
    "            action = prob.multinomial(num_samples=1).detach()\n",
    "            state, reward, done, current_state_id, collide = env.step(action[0, 0])\n",
    "            #print('current_state_id:', current_state_id)\n",
    "            state = torch.tensor(state).to(device)\n",
    "            if done:\n",
    "                break\n",
    "        ep_lengths.append(episode_length)\n",
    "\n",
    "\n",
    "num_fail = 0\n",
    "for jj in range(NUM_EVAL_EPISODES*5):\n",
    "    if ep_lengths[jj] == 500:\n",
    "        num_fail = num_fail + 1\n",
    "SR = 1 - num_fail / NUM_EVAL_EPISODES/5\n",
    "print('SR:', SR * 100)\n",
    "\n",
    "\n",
    "\n",
    "SPL = 0\n",
    "for ii in range(NUM_EVAL_EPISODES * 5):\n",
    "    if ep_lengths[ii] != 500:\n",
    "        SPL = SPL + min_length[ii] / ep_lengths[ii]\n",
    "SPL = SPL / NUM_EVAL_EPISODES * 100/5\n",
    "print('SPL:', SPL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
